# distributed-web-crawler

# File Descriptions:

`README.md`: The README file for the project. This is where you should include a brief introduction to the project, installation instructions, usage instructions, and other relevant information about the project.
app.py: The main script for the project. This script allows the user to interact with the command-line interface and choose between scraping or crawling.
generate_urls.py: A module that generates a list of URLs for the crawler to use.
scraper.py: A module that contains functions for scraping a website.
content.py: A module that contains a function to check if a file exists and print its content.
node.py: A module that defines a Flask app and serves as the endpoint for the scraper and crawler.
crawler.py: A module that contains functions for crawling a website.
storage/: A directory where the scraped data is stored.
requirements.txt: A file that lists the required packages for the project.
